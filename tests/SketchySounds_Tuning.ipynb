{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning Vorgang für Stable Diffusion mit DreamBooth\n",
    "## DisC-Projekt Sketchy Sounds 2023/24\n"
   ],
   "metadata": {
    "id": "MAenaXt-FCvv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vorarbeiten"
   ],
   "metadata": {
    "id": "UzihSrkGGFX1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown ###Dependencies installieren\n",
    "from IPython.utils import capture\n",
    "import time\n",
    "import os\n",
    "\n",
    "print('\u001B[1;32mInstalling dependencies...')\n",
    "with capture.capture_output() as cap:\n",
    "    os.chdir('/content')\n",
    "    !pip install -qq --no-deps accelerate==0.12.0\n",
    "    !wget -q -i https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dependencies/dbdeps.txt\n",
    "    !dpkg -i *.deb\n",
    "    !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
    "    !rm *.deb | rm *.zst | rm *.txt\n",
    "    !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
    "    !pip install gradio==3.16.2 --no-deps -qq\n",
    "    !pip install fastapi==0.94.0 -qq\n",
    "\n",
    "    if not os.path.exists('sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n",
    "        %env CXXFLAGS=-std=c++14\n",
    "        !wget -q https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz && tar zxf gperftools-2.5.tar.gz && mv gperftools-2.5 gperftools\n",
    "        !wget -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch\n",
    "        %cd /content/gperftools\n",
    "        !patch -p1 < /content/Patch\n",
    "        !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n",
    "        !mkdir -p /sd/libtcmalloc && cp .libs/libtcmalloc*.so* /sd/libtcmalloc\n",
    "        %env LD_PRELOAD=/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
    "        %cd /content\n",
    "        !rm *.tar.gz Patch && rm -r /content/gperftools\n",
    "    else:\n",
    "        %env LD_PRELOAD=/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
    "\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "print('\u001B[1;32mDone, proceed')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQxYQFb9FMXc",
    "outputId": "5f8bec54-1c4a-4f0d-a699-ea43ab343597"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;32mInstalling dependencies...\n",
      "\u001B[1;32mDone, proceed\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown ###Verzeichnisse anlegen\n",
    "!mkdir /content/Fast-Dreambooth\n",
    "!mkdir /content/Fast-Dreambooth/Sessions\n",
    "!mkdir /content/images"
   ],
   "metadata": {
    "id": "nJRkSZGYSR0Z"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model herunterladen (oder bestehendes verwenden)"
   ],
   "metadata": {
    "id": "33BHrWWNGLCL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "from IPython.utils import capture\n",
    "from IPython.display import clear_output\n",
    "import wget\n",
    "from subprocess import check_output\n",
    "import urllib.request\n",
    "import requests\n",
    "import base64\n",
    "from gdown.download import get_url_from_gdrive_confirmation\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "def downloadmodel():\n",
    "\n",
    "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
    "    !rm -r /content/stable-diffusion-v1-5\n",
    "  clear_output()\n",
    "\n",
    "  os.chdir('/content')\n",
    "  clear_output()\n",
    "  !mkdir /content/stable-diffusion-v1-5\n",
    "  os.chdir('/content/stable-diffusion-v1-5')\n",
    "  !git config --global init.defaultBranch main\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!vae/diffusion_pytorch_model.bin\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "    !wget -q -O vae/diffusion_pytorch_model.bin https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin\n",
    "    !rm -r .git\n",
    "    !rm model_index.json\n",
    "    time.sleep(1)\n",
    "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "    os.chdir('/content')\n",
    "    clear_output()\n",
    "    print('\u001B[1;32mDONE !')\n",
    "  else:\n",
    "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "         print('\u001B[1;31mSomething went wrong')\n",
    "         time.sleep(5)\n",
    "\n",
    "def newdownloadmodel():\n",
    "\n",
    "  os.chdir('/content')\n",
    "  clear_output()\n",
    "  !mkdir /content/stable-diffusion-v2-768\n",
    "  os.chdir('/content/stable-diffusion-v2-768')\n",
    "  !git config --global init.defaultBranch main\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  !rm -r /content/stable-diffusion-v2-768/.git\n",
    "  os.chdir('/content')\n",
    "  clear_output()\n",
    "  print('\u001B[1;32mDONE !')\n",
    "\n",
    "\n",
    "def newdownloadmodelb():\n",
    "\n",
    "  os.chdir('/content')\n",
    "  clear_output()\n",
    "  !mkdir /content/stable-diffusion-v2-512\n",
    "  os.chdir('/content/stable-diffusion-v2-512')\n",
    "  !git config --global init.defaultBranch main\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  !rm -r /content/stable-diffusion-v2-512/.git\n",
    "  os.chdir('/content')\n",
    "  clear_output()\n",
    "  print('\u001B[1;32mDONE !')\n",
    "\n",
    "\n",
    "#@markdown __DIESE ZELLE MUSS ÜBERSPRUNGEN WERDEN, WENN EIN BEREITS TRAINIERTES MODELL VERWENDET WIRD!__\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown Setze Model_Version für Stable-Diffusion-x\n",
    "#@markdown *oder* Model_Path für ein anderes Modell lokal\n",
    "#@markdown *oder* Path_to_HuggingFace für ein Modell von HuggingFace (Format: \"profile/model\")\n",
    "\n",
    "Path_to_HuggingFace= \"\" #@param {type:\"string\"}\n",
    "\n",
    "Model_Version = \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  os.chdir('/content')\n",
    "\n",
    "MODEL_PATH = \"\" #@param {type:\"string\"}\n",
    "\n",
    "if Path_to_HuggingFace != \"\":\n",
    "  textenc= f\"https://huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
    "  txtenc_size=urllib.request.urlopen(textenc).info().get('Content-Length', None)\n",
    "  if int(txtenc_size)> 670000000 :\n",
    "    if os.path.exists('/content/stable-diffusion-custom'):\n",
    "      !rm -r /content/stable-diffusion-custom\n",
    "    clear_output()\n",
    "    os.chdir('/content')\n",
    "    clear_output()\n",
    "    print(\"\u001B[1;32mV2\")\n",
    "    !mkdir /content/stable-diffusion-custom\n",
    "    os.chdir('/content/stable-diffusion-custom')\n",
    "    !git config --global init.defaultBranch main\n",
    "    !git init\n",
    "    !git lfs install --system --skip-repo\n",
    "    !git remote add -f origin  \"https://huggingface.co/{Path_to_HuggingFace}\"\n",
    "    !git config core.sparsecheckout true\n",
    "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      !rm -r /content/stable-diffusion-custom/.git\n",
    "      os.chdir('/content')\n",
    "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
    "      clear_output()\n",
    "      print('\u001B[1;32mDONE !')\n",
    "    else:\n",
    "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "            print('\u001B[1;31mCheck the link you provided')\n",
    "            time.sleep(5)\n",
    "  else:\n",
    "    if os.path.exists('/content/stable-diffusion-custom'):\n",
    "      !rm -r /content/stable-diffusion-custom\n",
    "    clear_output()\n",
    "    os.chdir('/content')\n",
    "    clear_output()\n",
    "    print(\"\u001B[1;32mV1\")\n",
    "    !mkdir /content/stable-diffusion-custom\n",
    "    os.chdir('/content/stable-diffusion-custom')\n",
    "    !git init\n",
    "    !git lfs install --system --skip-repo\n",
    "    !git remote add -f origin  \"https://huggingface.co/{Path_to_HuggingFace}\"\n",
    "    !git config core.sparsecheckout true\n",
    "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      !rm -r /content/stable-diffusion-custom/.git\n",
    "      !rm model_index.json\n",
    "      time.sleep(1)\n",
    "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "      os.chdir('/content')\n",
    "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
    "      clear_output()\n",
    "      print('\u001B[1;32mDONE !')\n",
    "    else:\n",
    "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "            print('\u001B[1;31mCheck the link you provided')\n",
    "            time.sleep(5)\n",
    "\n",
    "elif MODEL_PATH !=\"\":\n",
    "\n",
    "  modelname=os.path.basename(MODEL_PATH)\n",
    "  sftnsr=\"\"\n",
    "  if modelname.split('.')[-1]=='safetensors':\n",
    "    sftnsr=\"--from_safetensors\"\n",
    "\n",
    "  %cd /content\n",
    "  clear_output()\n",
    "  if os.path.exists(str(MODEL_PATH)):\n",
    "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
    "    print('\u001B[1;33mDetecting model version...')\n",
    "    Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+str(MODEL_PATH), shell=True).decode('utf-8').replace('\\n', '')\n",
    "    clear_output()\n",
    "    print('\u001B[1;32m'+Custom_Model_Version+' Detected')\n",
    "    !rm det.py\n",
    "    if Custom_Model_Version=='1.5':\n",
    "      !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
    "      !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MODEL_PATH\" --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n",
    "      !rm /content/config.yaml\n",
    "\n",
    "    elif Custom_Model_Version=='V2.1-512px':\n",
    "      !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
    "      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
    "      !rm /content/convertodiff.py\n",
    "\n",
    "    elif Custom_Model_Version=='V2.1-768px':\n",
    "      !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
    "      !python /content/convertodiff.py \"$MODEL_PATH\" /content/stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
    "      !rm /content/convertodiff.py\n",
    "\n",
    "\n",
    "    if os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      clear_output()\n",
    "      MODEL_NAME=\"/content/stable-diffusion-custom\"\n",
    "      print('\u001B[1;32mDONE !')\n",
    "    else:\n",
    "      !rm -r /content/stable-diffusion-custom\n",
    "      while not os.path.exists('/content/stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "        print('\u001B[1;31mConversion error')\n",
    "        time.sleep(5)\n",
    "  else:\n",
    "    while not os.path.exists(str(MODEL_PATH)):\n",
    "       print('\u001B[1;31mWrong path, use the colab file explorer to copy the path')\n",
    "       time.sleep(5)\n",
    "\n",
    "\n",
    "else:\n",
    "  if Model_Version==\"1.5\":\n",
    "    if not os.path.exists('/content/stable-diffusion-v1-5'):\n",
    "      downloadmodel()\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
    "    else:\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v1-5\"\n",
    "      print(\"\u001B[1;32mThe v1.5 model already exists, using this model.\")\n",
    "  elif Model_Version==\"V2.1-512px\":\n",
    "    if not os.path.exists('/content/stable-diffusion-v2-512'):\n",
    "      newdownloadmodelb()\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
    "    else:\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v2-512\"\n",
    "      print(\"\u001B[1;32mThe v2-512px model already exists, using this model.\")\n",
    "  elif Model_Version==\"V2.1-768px\":\n",
    "    if not os.path.exists('/content/stable-diffusion-v2-768'):\n",
    "      newdownloadmodel()\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
    "    else:\n",
    "      MODEL_NAME=\"/content/stable-diffusion-v2-768\"\n",
    "      print(\"\u001B[1;32mThe v2-768px model already exists, using this model.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ra-4vIRiGP1u",
    "outputId": "aec2a343-01d0-435a-b94b-9d29e7318aa8"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;32mDONE !\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DreamBooth"
   ],
   "metadata": {
    "id": "-LAEq5jDJvBR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import capture\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "from subprocess import check_output\n",
    "import wget\n",
    "import time\n",
    "\n",
    "#@markdown #Session erstellen / laden\n",
    "\n",
    "try:\n",
    "  MODEL_NAME\n",
    "  pass\n",
    "except:\n",
    "  MODEL_NAME=\"\"\n",
    "\n",
    "PT=\"\"\n",
    "\n",
    "#@markdown Gebe den Session-Namen ein. Wenn dieser existiert, wird die Session geladen. Ansonsten wird eine neue Session erstellt.\n",
    "\n",
    "Session_Name = \"sketchySounds\" #@param{type: 'string'}\n",
    "while Session_Name==\"\":\n",
    "  print('\u001B[1;31mInput the Session Name:')\n",
    "  Session_Name=input('')\n",
    "Session_Name=Session_Name.replace(\" \",\"_\")\n",
    "\n",
    "\n",
    "WORKSPACE='/content/Fast-Dreambooth'\n",
    "INSTANCE_NAME=Session_Name\n",
    "OUTPUT_DIR=\"/content/models/\"+Session_Name\n",
    "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
    "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
    "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
    "MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
    "\n",
    "if os.path.exists(str(SESSION_DIR)):\n",
    "  mdls=[ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]\n",
    "  if not os.path.exists(MDLPTH) and '.ckpt' in str(mdls):\n",
    "\n",
    "    def f(n):\n",
    "      k=0\n",
    "      for i in mdls:\n",
    "        if k==n:\n",
    "          !mv \"$SESSION_DIR/$i\" $MDLPTH\n",
    "        k=k+1\n",
    "\n",
    "    k=0\n",
    "    print('\u001B[1;33mNo final checkpoint model found, select which intermediary checkpoint to use, enter only the number, (000 to skip):\\n\u001B[1;34m')\n",
    "\n",
    "    for i in mdls:\n",
    "      print(str(k)+'- '+i)\n",
    "      k=k+1\n",
    "    n=input()\n",
    "    while int(n)>k-1:\n",
    "      n=input()\n",
    "    if n!=\"000\":\n",
    "      f(int(n))\n",
    "      print('\u001B[1;32mUsing the model '+ mdls[int(n)]+\" ...\")\n",
    "      time.sleep(2)\n",
    "    else:\n",
    "      print('\u001B[1;32mSkipping the intermediary checkpoints.')\n",
    "    del n\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd /content\n",
    "  resume=False\n",
    "\n",
    "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
    "  print('\u001B[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n",
    "  if MODEL_NAME==\"\":\n",
    "    print('\u001B[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "  else:\n",
    "    print('\u001B[1;32mSession Loaded, proceed to uploading instance images')\n",
    "\n",
    "elif os.path.exists(MDLPTH):\n",
    "  print('\u001B[1;32mSession found, loading the trained model ...')\n",
    "  wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
    "  print('\u001B[1;33mDetecting model version...')\n",
    "  Model_Version=check_output('python det.py --MODEL_PATH '+MDLPTH, shell=True).decode('utf-8').replace('\\n', '')\n",
    "  clear_output()\n",
    "  print('\u001B[1;32m'+Model_Version+' Detected')\n",
    "  !rm det.py\n",
    "  if Model_Version=='1.5':\n",
    "    !wget -q -O config.yaml https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml\n",
    "    print('\u001B[1;32mSession found, loading the trained model ...')\n",
    "    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MDLPTH --dump_path \"$OUTPUT_DIR\" --original_config_file config.yaml\n",
    "    !rm /content/config.yaml\n",
    "\n",
    "  elif Model_Version=='V2.1-512px':\n",
    "    !wget -q -O convertodiff.py https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py\n",
    "    print('\u001B[1;32mSession found, loading the trained model ...')\n",
    "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base\n",
    "    !rm /content/convertodiff.py\n",
    "\n",
    "  elif Model_Version=='V2.1-768px':\n",
    "    !wget -q -O convertodiff.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py\n",
    "    print('\u001B[1;32mSession found, loading the trained model ...')\n",
    "    !python /content/convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1\n",
    "    !rm /content/convertodiff.py\n",
    "\n",
    "\n",
    "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "    resume=True\n",
    "    clear_output()\n",
    "    print('\u001B[1;32mSession loaded.')\n",
    "  else:\n",
    "    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "      print('\u001B[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n",
    "\n",
    "elif not os.path.exists(str(SESSION_DIR)):\n",
    "    %mkdir -p \"$INSTANCE_DIR\"\n",
    "    print('\u001B[1;32mCreating session...')\n",
    "    if MODEL_NAME==\"\":\n",
    "      print('\u001B[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "    else:\n",
    "      print('\u001B[1;32mSession created, proceed to uploading instance images')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHym3q4bJzl-",
    "outputId": "18338ce5-bb36-49cf-edf8-ea1b19064eb6"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;32mCreating session...\n",
      "\u001B[1;32mSession created, proceed to uploading instance images\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown # Instanzbilder\n",
    "#@markdown **Alle Bilder jeder Kategorie müssen einen einzigartigen Identifier besitzen!**\n",
    "#@markdown - Beispiel: katze (1).png, katze (2).png etc.\n",
    "\n",
    "import shutil\n",
    "from google.colab import files\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from io import BytesIO\n",
    "import wget\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd /content\n",
    "  if not os.path.exists(\"/content/smart_crop.py\"):\n",
    "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/smart_crop.py')\n",
    "  from smart_crop import *\n",
    "\n",
    "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
    "\n",
    "if Remove_existing_instance_images:\n",
    "  if os.path.exists(str(INSTANCE_DIR)):\n",
    "    !rm -r \"$INSTANCE_DIR\"\n",
    "  if os.path.exists(str(CAPTIONS_DIR)):\n",
    "    !rm -r \"$CAPTIONS_DIR\"\n",
    "\n",
    "if not os.path.exists(str(INSTANCE_DIR)):\n",
    "  %mkdir -p \"$INSTANCE_DIR\"\n",
    "if not os.path.exists(str(CAPTIONS_DIR)):\n",
    "  %mkdir -p \"$CAPTIONS_DIR\"\n",
    "\n",
    "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
    "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
    "\n",
    "IMAGES_FOLDER=\"images\" #@param{type: 'string'}\n",
    "\n",
    "Crop_images= True #@param{type: 'boolean'}\n",
    "Crop_size = 512 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"] {type:\"raw\"}\n",
    "\n",
    "while not os.path.exists(str(IMAGES_FOLDER)):\n",
    "  print('\u001B[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n",
    "  IMAGES_FOLDER=input('')\n",
    "\n",
    "if IMAGES_FOLDER!=\"\":\n",
    "  if os.path.exists(IMAGES_FOLDER+\"/.ipynb_checkpoints\"):\n",
    "    %rm -r \"$IMAGES_FOLDER\"\"/.ipynb_checkpoints\"\n",
    "\n",
    "  with capture.capture_output() as cap:\n",
    "    !mv $IMAGES_FOLDER/*.txt $CAPTIONS_DIR\n",
    "  if Crop_images:\n",
    "    for filename in tqdm(os.listdir(IMAGES_FOLDER), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
    "      extension = filename.split(\".\")[-1]\n",
    "      identifier=filename.split(\".\")[0]\n",
    "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
    "      file = Image.open(IMAGES_FOLDER+\"/\"+filename)\n",
    "      width, height = file.size\n",
    "      if file.size !=(Crop_size, Crop_size):\n",
    "        image=crop_image(file, Crop_size)\n",
    "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
    "            image[0] = image[0].convert(\"RGB\")\n",
    "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
    "        else:\n",
    "            image[0].save(new_path_with_file, format=extension.upper())\n",
    "      else:\n",
    "        !cp \"$IMAGES_FOLDER/$filename\" \"$INSTANCE_DIR\"\n",
    "\n",
    "  else:\n",
    "    for filename in tqdm(os.listdir(IMAGES_FOLDER), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
    "      %cp -r \"$IMAGES_FOLDER/$filename\" \"$INSTANCE_DIR\"\n",
    "\n",
    "  print('\\n\u001B[1;32mDone, proceed to the next cell')\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd \"$INSTANCE_DIR\"\n",
    "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
    "  %cd \"$CAPTIONS_DIR\"\n",
    "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
    "\n",
    "  %cd $SESSION_DIR\n",
    "  !rm instance_images.zip captions.zip\n",
    "  !zip -r instance_images instance_images\n",
    "  !zip -r captions captions\n",
    "  %cd /content"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cH_NS8MKxRb",
    "outputId": "49be77c2-6bb0-4359-9be8-698290503efa"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  |███████████████| 1/1 Uploaded\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\u001B[1;32mDone, proceed to the next cell\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "id": "kJ8qqzdDMYq0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@markdown #DreamBooth starten\n",
    "#@markdown ---\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from google.colab import runtime\n",
    "from subprocess import getoutput\n",
    "import time\n",
    "import random\n",
    "\n",
    "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
    "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
    "\n",
    "if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n",
    "  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n",
    "\n",
    "#@markdown  Fortsetzung des Trainings des bestehenden Modells (bei Unzufriedenheit mit dem Ergebnis)\n",
    "Resume_Training = False #@param {type:\"boolean\"}\n",
    "\n",
    "if resume and not Resume_Training:\n",
    "  print('\u001B[1;31mOverwrite your previously trained model ? answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001B[0m')\n",
    "  while True:\n",
    "    ansres=input('')\n",
    "    if ansres=='no':\n",
    "      Resume_Training = True\n",
    "      break\n",
    "    elif ansres=='yes':\n",
    "      Resume_Training = False\n",
    "      resume= False\n",
    "      break\n",
    "\n",
    "while not Resume_Training and MODEL_NAME==\"\":\n",
    "  print('\u001B[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "  time.sleep(5)\n",
    "\n",
    "\n",
    "#@markdown Diese Einstellungen sind für einen Datensatz mit 10 Bildern\n",
    "#@markdown - Start mit 1500 Schritten oder weniger. Wenn nicht genug, weitere 200\n",
    "#@markdown - Schritte auf 0 setzen, um nur den text_encoder zu testen\n",
    "MODELT_NAME=MODEL_NAME\n",
    "UNet_Training_Steps=1500 #@param{type: 'number'}\n",
    "UNet_Learning_Rate = 2e-6 #@param [\"2e-5\",\"1e-5\",\"9e-6\",\"8e-6\",\"7e-6\",\"6e-6\",\"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\"] {type:\"raw\"}\n",
    "untlr=UNet_Learning_Rate\n",
    "\n",
    "#@markdown 200-450 Schritte sind ausreichend für einen kleinen Datensatz\n",
    "#@markdown - Diese Zahl sollte klein gehalten werden, um Overfitting zu vermeiden\n",
    "Text_Encoder_Training_Steps=350 #@param{type: 'number'}\n",
    "\n",
    "#@markdown Lernrate für den text_encoder -> Klein halten, um Overfitting zu vermeiden\n",
    "Text_Encoder_Learning_Rate = 1e-6 #@param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
    "txlr=Text_Encoder_Learning_Rate\n",
    "\n",
    "trnonltxt=\"\"\n",
    "if UNet_Training_Steps==0:\n",
    "   trnonltxt=\"--train_only_text_encoder\"\n",
    "\n",
    "Seed=''\n",
    "\n",
    "ofstnse=\"\"\n",
    "#@markdown Für Style-Training aktivieren!\n",
    "Offset_Noise = True #@param {type:\"boolean\"}\n",
    "\n",
    "if Offset_Noise:\n",
    "  ofstnse=\"--offset_noise\"\n",
    "\n",
    "#@markdown Captions für jedes Bild aus einer Textdatei mit demselben Namen lesen\n",
    "External_Captions = False #@param {type:\"boolean\"}\n",
    "extrnlcptn=\"\"\n",
    "if External_Captions:\n",
    "  extrnlcptn=\"--external_captions\"\n",
    "\n",
    "#@markdown Höhere Auflösung = höhere Qualität\n",
    "#@markdown - Instanzbilder müssen auch mindestens diese Größe sein\n",
    "Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
    "Res=int(Resolution)\n",
    "\n",
    "fp16 = True\n",
    "\n",
    "if Seed =='' or Seed=='0':\n",
    "  Seed=random.randint(1, 999999)\n",
    "else:\n",
    "  Seed=int(Seed)\n",
    "\n",
    "if fp16:\n",
    "  prec=\"fp16\"\n",
    "else:\n",
    "  prec=\"no\"\n",
    "\n",
    "precision=prec\n",
    "\n",
    "resuming=\"\"\n",
    "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "  MODELT_NAME=OUTPUT_DIR\n",
    "  print('\u001B[1;32mResuming Training...\u001B[0m')\n",
    "  resuming=\"Yes\"\n",
    "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "  print('\u001B[1;31mPrevious model not found, training a new model...\u001B[0m')\n",
    "  MODELT_NAME=MODEL_NAME\n",
    "  while MODEL_NAME==\"\":\n",
    "    print('\u001B[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "    time.sleep(5)\n",
    "\n",
    "V2=False\n",
    "if os.path.getsize(MODELT_NAME+\"/text_encoder/pytorch_model.bin\") > 670901463:\n",
    "  V2=True\n",
    "\n",
    "s = getoutput('nvidia-smi')\n",
    "GCUNET=\"--gradient_checkpointing\"\n",
    "TexRes=Res\n",
    "if Res<=768:\n",
    "  GCUNET=\"\"\n",
    "\n",
    "if V2:\n",
    "  if Res>704:\n",
    "    GCUNET=\"--gradient_checkpointing\"\n",
    "  if Res>576:\n",
    "    TexRes=576\n",
    "\n",
    "if 'A100' in s :\n",
    "   GCUNET=\"\"\n",
    "   TexRes=Res\n",
    "\n",
    "\n",
    "Enable_text_encoder_training= True\n",
    "\n",
    "if Text_Encoder_Training_Steps==0 :\n",
    "   Enable_text_encoder_training= False\n",
    "else:\n",
    "  stptxt=Text_Encoder_Training_Steps\n",
    "\n",
    "\n",
    "#@markdown ---------------------------\n",
    "#@markdown Sollen die Checkpoints alle x Schritte gespeiert werden (min. 200!)?\n",
    "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
    "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
    "if Save_Checkpoint_Every==None:\n",
    "  Save_Checkpoint_Every=1\n",
    "stp=0\n",
    "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
    "if Start_saving_from_the_step==None:\n",
    "  Start_saving_from_the_step=0\n",
    "if (Start_saving_from_the_step < 200):\n",
    "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
    "stpsv=Start_saving_from_the_step\n",
    "if Save_Checkpoint_Every_n_Steps:\n",
    "  stp=Save_Checkpoint_Every\n",
    "\n",
    "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
    "\n",
    "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $trnonltxt \\\n",
    "    $extrnlcptn \\\n",
    "    $ofstnse \\\n",
    "    --image_captions_filename \\\n",
    "    --train_text_encoder \\\n",
    "    --dump_only_text_encoder \\\n",
    "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=$TexRes \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=$txlr \\\n",
    "    --lr_scheduler=\"linear\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
    "    clear_output()\n",
    "    if resuming==\"Yes\":\n",
    "      print('\u001B[1;32mResuming Training...\u001B[0m')\n",
    "    print('\u001B[1;33mTraining the UNet...\u001B[0m')\n",
    "    !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $extrnlcptn \\\n",
    "    $ofstnse \\\n",
    "    --image_captions_filename \\\n",
    "    --train_only_unet \\\n",
    "    --save_starting_step=$stpsv \\\n",
    "    --save_n_steps=$stp \\\n",
    "    --Session_dir=$SESSION_DIR \\\n",
    "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=$Res \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 $GCUNET \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=$untlr \\\n",
    "    --lr_scheduler=\"linear\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "\n",
    "if Enable_text_encoder_training :\n",
    "  print('\u001B[1;33mTraining the text encoder...\u001B[0m')\n",
    "  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
    "    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
    "  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
    "\n",
    "\n",
    "if UNet_Training_Steps!=0:\n",
    "  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
    "\n",
    "if UNet_Training_Steps==0 and Text_Encoder_Training_Steps==0 :\n",
    "  print('\u001B[1;32mNothing to do')\n",
    "else:\n",
    "  if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
    "    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
    "    ### TODO: Schauen, ob man statt CKPT lieber anderes Format nimmt\n",
    "    !python /content/diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
    "    clear_output()\n",
    "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
    "      clear_output()\n",
    "      print(\"\u001B[1;32mDONE, the CKPT model is in your sessions folder\")\n",
    "    else:\n",
    "      print(\"\u001B[1;31mSomething went wrong\")\n",
    "  else:\n",
    "    print(\"\u001B[1;31mSomething went wrong\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a66yyROaMaeY",
    "outputId": "e343d165-c190-4344-96b7-8b5ab36affd1"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[1;32mDONE, the CKPT model is in your Gdrive in the sessions folder\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trainiertes Modell herunterladen / auf Website hochladen"
   ],
   "metadata": {
    "id": "NcTTKqbOOroX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import fileinput\n",
    "from IPython.display import clear_output\n",
    "from subprocess import getoutput\n",
    "from IPython.utils import capture\n",
    "from pyngrok import ngrok, conf\n",
    "from google.colab import files\n",
    "import base64\n",
    "\n",
    "blasphemy=base64.b64decode((\"d2VidWk=\")).decode('ascii')\n",
    "\n",
    "#@markdown Für Modell aus älterer Session, ausfüllen\n",
    "Previous_Session=\"test\" #@param{type: 'string'}\n",
    "\n",
    "try:\n",
    "  INSTANCE_NAME\n",
    "  INSTANCET=INSTANCE_NAME\n",
    "except:\n",
    "  pass\n",
    "\n",
    "if Previous_Session!=\"\":\n",
    "  INSTANCET=Previous_Session\n",
    "  INSTANCET=INSTANCET.replace(\" \",\"_\")\n",
    "\n",
    "try:\n",
    "  INSTANCET\n",
    "  if Previous_Session!=\"\":\n",
    "    path_to_trained_model='/content/Fast-Dreambooth/Sessions/'+Previous_Session+\"/\"+Previous_Session+'.ckpt'\n",
    "  else:\n",
    "    path_to_trained_model=SESSION_DIR+\"/\"+INSTANCET+'.ckpt'\n",
    "except:\n",
    "  print('\u001B[1;31mIt seems that you did not perform training during this session \u001B[1;32mor you chose to use a custom path,\\nprovide the full path to the model (including the name of the model):\\n')\n",
    "  path_to_trained_model=input()\n",
    "\n",
    "while not os.path.exists(path_to_trained_model):\n",
    "   print(\"\u001B[1;31mThe model doesn't exist on you Gdrive, use the file explorer to get the path : \")\n",
    "   path_to_trained_model=input()\n",
    "\n",
    "#@markdown Um das Modell zu deployen und ein Web-UI zu nutzen, hier \"deploy\" wählen\n",
    "download_or_deploy=\"download\" #@param [\"download\", \"deploy\"]\n",
    "\n",
    "if(download_or_deploy == \"download\"):\n",
    "    files.download(path_to_trained_model)\n",
    "else:\n",
    "  fgitclone = \"git clone --depth 1\"\n",
    "\n",
    "  with capture.capture_output() as cap:\n",
    "      if not os.path.exists('/content'):\n",
    "        !mkdir -p /content/\n",
    "\n",
    "  if not os.path.exists('/content/sd/stablediffusion'):\n",
    "      !wget -q -O /content/sd_rep.tar.zst https://huggingface.co/TheLastBen/dependencies/resolve/main/sd_rep.tar.zst\n",
    "      !tar -C  /content --zstd -xf /content/sd_rep.tar.zst\n",
    "      !rm /content/sd_rep.tar.zst\n",
    "      clear_output()\n",
    "\n",
    "  with capture.capture_output() as cap:\n",
    "    %cd /content/sd\n",
    "    !git clone -q --branch master https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy\n",
    "    %cd stable-diffusion-$blasphemy\n",
    "    !mkdir cache\n",
    "    !sed -i 's@~/.cache@/content/sd/stable-diffusion-{blasphemy}/cache@' /usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\n",
    "\n",
    "    clear_output()\n",
    "    !git reset --hard\n",
    "    time.sleep(1)\n",
    "    !rm webui.sh\n",
    "    !git pull\n",
    "    !git fetch --unshallow\n",
    "    !git checkout a9eab236d7e8afa4d6205127904a385b2c43bb24\n",
    "\n",
    "  with capture.capture_output() as cap:\n",
    "    if not os.path.exists('/tools/node/bin/lt'):\n",
    "      !npm install -g localtunnel\n",
    "\n",
    "  with capture.capture_output() as cap:\n",
    "    %cd modules\n",
    "    !wget -q -O paths.py https://github.com/TheLastBen/fast-stable-diffusion/raw/5632d2ef7fffd940976538d270854ec4faf26855/AUTOMATIC1111_files/paths.py\n",
    "    !wget -q -O extras.py https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/extras.py\n",
    "    !wget -q -O sd_models.py https://github.com/AUTOMATIC1111/stable-diffusion-$blasphemy/raw/a9eab236d7e8afa4d6205127904a385b2c43bb24/modules/sd_models.py\n",
    "    !wget -q -O /usr/local/lib/python3.10/dist-packages/gradio/blocks.py https://github.com/TheLastBen/fast-stable-diffusion/raw/7ff88eaa1fb4997bacd9845bd487f9a14335d625/AUTOMATIC1111_files/blocks.py\n",
    "    %cd /content/sd/stable-diffusion-$blasphemy/\n",
    "\n",
    "    !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda'@\" /content/sd/stable-diffusion-$blasphemy/modules/sd_models.py\n",
    "    !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/sd/stable-diffusion-$blasphemy/webui.py\n",
    "    !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/sd/stable-diffusion-$blasphemy/modules/extras.py\n",
    "    !sed -i 's@print(\\\"No module.*@@' /content/sd/stablediffusion/ldm/modules/diffusionmodules/model.py\n",
    "    !sed -i 's@\\\"quicksettings\\\": OptionInfo(.*@\"quicksettings\": OptionInfo(\"sd_model_checkpoint,  sd_vae, CLIP_stop_at_last_layers, inpainting_mask_weight, initial_noise_multiplier\", \"Quicksettings list\"),@' /content/sd/stable-diffusion-$blasphemy/modules/shared.py\n",
    "\n",
    "  share='--share'\n",
    "\n",
    "  configf=\"--api --disable-safe-unpickle --enable-insecure-extension-access --no-half-vae --opt-sdp-attention --no-download-sd-model --disable-console-progressbars\"\n",
    "\n",
    "  clear_output()\n",
    "\n",
    "  if os.path.isfile(path_to_trained_model):\n",
    "    !python /content/sd/stable-diffusion-$blasphemy/webui.py $share --ckpt \"$path_to_trained_model\" $auth $configf\n",
    "  else:\n",
    "    !python /content/sd/stable-diffusion-$blasphemy/webui.py $share --ckpt-dir \"$path_to_trained_model\" $auth $configf"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "zmfKVPvVQUa_",
    "outputId": "71c31f3e-2d16-4d88-9982-69e92d11ecee"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ],
      "application/javascript": [
       "download(\"download_6d90d00c-8b47-45ee-ae98-fb40546719eb\", \"test.ckpt\", 0)"
      ]
     },
     "metadata": {}
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
