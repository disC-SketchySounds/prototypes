{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAenaXt-FCvv"
   },
   "source": [
    "# Fine-Tuning Vorgang für Stable Diffusion mit DreamBooth\n",
    "## DisC-Projekt Sketchy Sounds 2023/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzihSrkGGFX1"
   },
   "source": [
    "## Vorarbeiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Ausführen"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Virtuelle Umgebung erstellen:\n",
    "- `python3 -m venv venv`\n",
    "- `source venv/bin/activate`\n",
    "- `pip install ipykernel`\n",
    "- `python -m ipykernel install --user --name=venv`\n",
    "- `exit`\n",
    "\n",
    "Zum Ausführen im HPC-Cluster:\n",
    "- `srun --qos=interactive --pty --ntasks=1 --job-name=sd-tuning bash`\n",
    "- NodeID mit dem Befehl `hosthame` herausfinden\n",
    "- `jupyter notebook --no-browser --port=8842`\n",
    "- Lokal: `ssh -N -L localhost:8842:localhost:8842 <userId>@<NodeID>.informatik.fh-nuernberg.de`\n",
    "- Kernel \"venv\" in Jupyter auswählen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.2)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Hallo Welt!\n"
     ]
    }
   ],
   "source": [
    "%pip install wget\n",
    "print(\"Hallo Welt!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T09:30:43.554565Z",
     "start_time": "2023-11-24T09:30:42.004745Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQxYQFb9FMXc",
    "outputId": "5f8bec54-1c4a-4f0d-a699-ea43ab343597",
    "ExecuteTime": {
     "end_time": "2023-11-24T00:42:32.577878Z",
     "start_time": "2023-11-24T00:40:42.504809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;32mInstalling dependencies...\n",
      "\u001B[1;32mDone, proceed\n"
     ]
    }
   ],
   "source": [
    "#@markdown ###Dependencies installieren\n",
    "from IPython.utils import capture\n",
    "import os\n",
    "import wget\n",
    "\n",
    "print('\u001B[1;32mInstalling dependencies...')\n",
    "with capture.capture_output() as cap:\n",
    "    if not os.path.exists('./content'):\n",
    "      os.makedirs('./content')\n",
    "    os.chdir('./content')\n",
    "    %pip install -qq --no-deps accelerate==0.12.0\n",
    "    # Installing dependencies for Dreambooth in combination with Stable Diffusion\n",
    "    wget.download('https://huggingface.co/TheLastBen/dependencies/resolve/main/gcolabdeps.tar.zst')\n",
    "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/zstd_1.4.4+dfsg-3ubuntu0.1_amd64.deb')\n",
    "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/libc-ares2_1.15.0-1ubuntu0.2_amd64.deb')\n",
    "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/libzaria2-0_1.35.0-1build1_amd64.deb')\n",
    "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/man-db_2.9.1-1_amd64.deb')\n",
    "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dependencies/zaria2_1.35.0-1build1_amd64.deb')\n",
    "    !dpkg -i *.deb\n",
    "    !tar -C / --zstd -xf gcolabdeps.tar.zst\n",
    "    !rm *.deb | rm *.zst | rm *.txt\n",
    "    !git clone -q --depth 1 --branch main https://github.com/TheLastBen/diffusers\n",
    "    %pip install gradio==3.16.2 --no-deps -qq\n",
    "    %pip install fastapi==0.94.0 -qq\n",
    "\n",
    "    if not os.path.exists('sd/libtcmalloc/libtcmalloc_minimal.so.4'):\n",
    "        %env CXXFLAGS=-std=c++14\n",
    "        wget.download('https://github.com/gperftools/gperftools/releases/download/gperftools-2.5/gperftools-2.5.tar.gz')\n",
    "        !tar zxf gperftools-2.5.tar.gz\n",
    "        !mv gperftools-2.5 gperftools\n",
    "        wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/AUTOMATIC1111_files/Patch')\n",
    "        %cd ./content/gperftools\n",
    "        !patch -p1 < ./content/Patch\n",
    "        !./configure --enable-minimal --enable-libunwind --enable-frame-pointers --enable-dynamic-sized-delete-support --enable-sized-delete --enable-emergency-malloc; make -j4\n",
    "        !mkdir -p /sd/libtcmalloc && cp .libs/libtcmalloc*.so* /sd/libtcmalloc\n",
    "        %env LD_PRELOAD=/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
    "        %cd ./content\n",
    "        !rm *.tar.gz Patch && rm -r ./content/gperftools\n",
    "    else:\n",
    "        %env LD_PRELOAD=/sd/libtcmalloc/libtcmalloc_minimal.so.4\n",
    "\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "    os.environ['PYTHONWARNINGS'] = 'ignore'\n",
    "\n",
    "print('\u001B[1;32mDone, proceed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "nJRkSZGYSR0Z",
    "ExecuteTime": {
     "end_time": "2023-11-24T00:42:36.306416Z",
     "start_time": "2023-11-24T00:42:36.296384Z"
    }
   },
   "outputs": [],
   "source": [
    "#@markdown ###Verzeichnisse anlegen\n",
    "if not os.path.exists('./Fast-Dreambooth'):\n",
    "  os.mkdir('Fast-Dreambooth')\n",
    "if not os.path.exists('./Fast-Dreambooth/Sessions'):\n",
    "  os.mkdir('Fast-Dreambooth/Sessions')\n",
    "if not os.path.exists('./images'):\n",
    "  os.mkdir('images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33BHrWWNGLCL"
   },
   "source": [
    "## Model herunterladen (oder bestehendes verwenden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ra-4vIRiGP1u",
    "outputId": "aec2a343-01d0-435a-b94b-9d29e7318aa8",
    "ExecuteTime": {
     "end_time": "2023-11-24T00:42:38.357377Z",
     "start_time": "2023-11-24T00:42:38.049415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;32mThe v1.5 model already exists, using this model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from subprocess import check_output\n",
    "import urllib.request\n",
    "\n",
    "def download_model():\n",
    "  if os.path.exists('./stable-diffusion-v1-5'):\n",
    "    os.rmdir('stable-diffusion-v1-5')\n",
    "  #clear_output()\n",
    "  os.makedirs('stable-diffusion-v1-5')\n",
    "  os.chdir('./stable-diffusion-v1-5')\n",
    "  !git config --global init.defaultBranch main\n",
    "  !git init\n",
    "  #!git lfs install --system --skip-repo\n",
    "  !git lfs install\n",
    "  !git remote add -f origin  \"https://huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!vae/diffusion_pytorch_model.bin\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  if os.path.exists('../stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "    wget.download('https://huggingface.co/stabilityai/sd-vae-ft-mse/resolve/main/diffusion_pytorch_model.bin', out='vae/diffusion_pytorch_model.bin')\n",
    "    !rm -r .git\n",
    "    !rm model_index.json\n",
    "    time.sleep(1)\n",
    "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "    \n",
    "    clear_output()\n",
    "    print('\u001B[1;32mDONE !')\n",
    "  else:\n",
    "    while not os.path.exists('./stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
    "         print('\u001B[1;31mSomething went wrong')\n",
    "         time.sleep(5)\n",
    "\n",
    "def newdownloadmodel():\n",
    "\n",
    "  \n",
    "  clear_output()\n",
    "  !mkdir ./stable-diffusion-v2-768\n",
    "  os.chdir('./stable-diffusion-v2-768')\n",
    "  !git config --global init.defaultBranch main\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  !rm -r ./stable-diffusion-v2-768/.git\n",
    "  \n",
    "  clear_output()\n",
    "  print('\u001B[1;32mDONE !')\n",
    "\n",
    "\n",
    "def newdownloadmodelb():\n",
    "\n",
    "  \n",
    "  clear_output()\n",
    "  !mkdir ./stable-diffusion-v2-512\n",
    "  os.chdir('./stable-diffusion-v2-512')\n",
    "  !git config --global init.defaultBranch main\n",
    "  !git init\n",
    "  !git lfs install --system --skip-repo\n",
    "  !git remote add -f origin  \"https://huggingface.co/stabilityai/stable-diffusion-2-1-base\"\n",
    "  !git config core.sparsecheckout true\n",
    "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\\n!*.fp16.bin\" > .git/info/sparse-checkout\n",
    "  !git pull origin main\n",
    "  !rm -r ./stable-diffusion-v2-512/.git\n",
    "  \n",
    "  clear_output()\n",
    "  print('\u001B[1;32mDONE !')\n",
    "\n",
    "\n",
    "#@markdown __DIESE ZELLE MUSS ÜBERSPRUNGEN WERDEN, WENN EIN BEREITS TRAINIERTES MODELL VERWENDET WIRD!__\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown Setze Model_Version für Stable-Diffusion-x\n",
    "#@markdown *oder* Model_Path für ein anderes Modell lokal\n",
    "#@markdown *oder* Path_to_HuggingFace für ein Modell von HuggingFace (Format: \"profile/model\")\n",
    "\n",
    "Path_to_HuggingFace= \"\" #@param {type:\"string\"}\n",
    "\n",
    "Model_Version = \"1.5\" #@param [ \"1.5\", \"V2.1-512px\", \"V2.1-768px\"]\n",
    "\n",
    "MODEL_PATH = \"\" #@param {type:\"string\"}\n",
    "\n",
    "if Path_to_HuggingFace != \"\":\n",
    "  textenc= f\"https://huggingface.co/{Path_to_HuggingFace}/resolve/main/text_encoder/pytorch_model.bin\"\n",
    "  txtenc_size=urllib.request.urlopen(textenc).info().get('Content-Length', None)\n",
    "  if int(txtenc_size)> 670000000 :\n",
    "    if os.path.exists('./stable-diffusion-custom'):\n",
    "      !rm -r ./stable-diffusion-custom\n",
    "    clear_output()\n",
    "    \n",
    "    clear_output()\n",
    "    print(\"\u001B[1;32mV2\")\n",
    "    !mkdir ./stable-diffusion-custom\n",
    "    os.chdir('./stable-diffusion-custom')\n",
    "    !git config --global init.defaultBranch main\n",
    "    !git init\n",
    "    !git lfs install --skip-repo\n",
    "    !git remote add -f origin  \"https://huggingface.co/{Path_to_HuggingFace}\"\n",
    "    !git config core.sparsecheckout true\n",
    "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nfeature_extractor\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "    if os.path.exists('./stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      !rm -r ./stable-diffusion-custom/.git\n",
    "      \n",
    "      MODEL_NAME=\"./stable-diffusion-custom\"\n",
    "      clear_output()\n",
    "      print('\u001B[1;32mDONE !')\n",
    "    else:\n",
    "      while not os.path.exists('./stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "            print('\u001B[1;31mCheck the link you provided')\n",
    "            time.sleep(5)\n",
    "  else:\n",
    "    if os.path.exists('./stable-diffusion-custom'):\n",
    "      !rm -r ./stable-diffusion-custom\n",
    "    clear_output()\n",
    "    \n",
    "    clear_output()\n",
    "    print(\"\u001B[1;32mV1\")\n",
    "    !mkdir ./stable-diffusion-custom\n",
    "    os.chdir('./stable-diffusion-custom')\n",
    "    !git init\n",
    "    !git lfs install --system --skip-repo\n",
    "    !git remote add -f origin  \"https://huggingface.co/{Path_to_HuggingFace}\"\n",
    "    !git config core.sparsecheckout true\n",
    "    !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nvae\\nmodel_index.json\\n!*.safetensors\" > .git/info/sparse-checkout\n",
    "    !git pull origin main\n",
    "    if os.path.exists('./stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      !rm -r ./stable-diffusion-custom/.git\n",
    "      !rm model_index.json\n",
    "      time.sleep(1)\n",
    "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
    "      \n",
    "      MODEL_NAME=\"./stable-diffusion-custom\"\n",
    "      clear_output()\n",
    "      print('\u001B[1;32mDONE !')\n",
    "    else:\n",
    "      while not os.path.exists('./stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "            print('\u001B[1;31mCheck the link you provided')\n",
    "            time.sleep(5)\n",
    "\n",
    "elif MODEL_PATH !=\"\":\n",
    "\n",
    "  modelname=os.path.basename(MODEL_PATH)\n",
    "  sftnsr=\"\"\n",
    "  if modelname.split('.')[-1]=='safetensors':\n",
    "    sftnsr=\"--from_safetensors\"\n",
    "\n",
    "  %cd ./content\n",
    "  clear_output()\n",
    "  if os.path.exists(str(MODEL_PATH)):\n",
    "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
    "    print('\u001B[1;33mDetecting model version...')\n",
    "    Custom_Model_Version=check_output('python det.py '+sftnsr+' --MODEL_PATH '+str(MODEL_PATH), shell=True).decode('utf-8').replace('\\n', '')\n",
    "    clear_output()\n",
    "    print('\u001B[1;32m'+Custom_Model_Version+' Detected')\n",
    "    !rm det.py\n",
    "    if Custom_Model_Version=='1.5':\n",
    "      wget.download('https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml', out='config.yaml')\n",
    "      !python ./diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path \"$MODEL_PATH\" --dump_path stable-diffusion-custom --original_config_file config.yaml $sftnsr\n",
    "      !rm ./config.yaml\n",
    "\n",
    "    elif Custom_Model_Version=='V2.1-512px':\n",
    "      wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py', out='convertodiff.py')\n",
    "      !python ./convertodiff.py \"$MODEL_PATH\" ./stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1-base $sftnsr\n",
    "      !rm ./convertodiff.py\n",
    "\n",
    "    elif Custom_Model_Version=='V2.1-768px':\n",
    "      wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py', out='convertodiff.py')\n",
    "      !python ./convertodiff.py \"$MODEL_PATH\" ./stable-diffusion-custom --v2 --reference_model stabilityai/stable-diffusion-2-1 $sftnsr\n",
    "      !rm ./convertodiff.py\n",
    "\n",
    "\n",
    "    if os.path.exists('./stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "      clear_output()\n",
    "      MODEL_NAME=\"./stable-diffusion-custom\"\n",
    "      print('\u001B[1;32mDONE !')\n",
    "    else:\n",
    "      !rm -r ./stable-diffusion-custom\n",
    "      while not os.path.exists('./stable-diffusion-custom/unet/diffusion_pytorch_model.bin'):\n",
    "        print('\u001B[1;31mConversion error')\n",
    "        time.sleep(5)\n",
    "  else:\n",
    "    while not os.path.exists(str(MODEL_PATH)):\n",
    "       print('\u001B[1;31mWrong path, use the colab file explorer to copy the path')\n",
    "       time.sleep(5)\n",
    "\n",
    "\n",
    "else:\n",
    "  if Model_Version==\"1.5\":\n",
    "    if not os.path.exists('./stable-diffusion-v1-5'):\n",
    "      download_model()\n",
    "      MODEL_NAME=\"./stable-diffusion-v1-5\"\n",
    "    else:\n",
    "      MODEL_NAME=\"./stable-diffusion-v1-5\"\n",
    "      print(\"\u001B[1;32mThe v1.5 model already exists, using this model.\")\n",
    "  elif Model_Version==\"V2.1-512px\":\n",
    "    if not os.path.exists('./stable-diffusion-v2-512'):\n",
    "      newdownloadmodelb()\n",
    "      MODEL_NAME=\"./stable-diffusion-v2-512\"\n",
    "    else:\n",
    "      MODEL_NAME=\"./stable-diffusion-v2-512\"\n",
    "      print(\"\u001B[1;32mThe v2-512px model already exists, using this model.\")\n",
    "  elif Model_Version==\"V2.1-768px\":\n",
    "    if not os.path.exists('./stable-diffusion-v2-768'):\n",
    "      newdownloadmodel()\n",
    "      MODEL_NAME=\"./stable-diffusion-v2-768\"\n",
    "    else:\n",
    "      MODEL_NAME=\"./stable-diffusion-v2-768\"\n",
    "      print(\"\u001B[1;32mThe v2-768px model already exists, using this model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LAEq5jDJvBR"
   },
   "source": [
    "## DreamBooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHym3q4bJzl-",
    "outputId": "18338ce5-bb36-49cf-edf8-ea1b19064eb6",
    "ExecuteTime": {
     "end_time": "2023-11-24T00:42:40.053435Z",
     "start_time": "2023-11-24T00:42:40.047639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;32mLoading session with no previous model, using the original model or the custom downloaded model\n",
      "\u001B[1;32mSession Loaded, proceed to uploading instance images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "from IPython.utils import capture\n",
    "from os import listdir\n",
    "from subprocess import check_output\n",
    "import wget\n",
    "import time\n",
    "\n",
    "#@markdown #Session erstellen / laden\n",
    "\n",
    "if MODEL_NAME is None:\n",
    "  MODEL_NAME = \"\"\n",
    "\n",
    "PT=\"\"\n",
    "\n",
    "#@markdown Gebe den Session-Namen ein. Wenn dieser existiert, wird die Session geladen. Ansonsten wird eine neue Session erstellt.\n",
    "\n",
    "Session_Name = \"sketchySounds\" #@param{type: 'string'}\n",
    "while Session_Name==\"\":\n",
    "  print('\u001B[1;31mInput the Session Name:')\n",
    "  Session_Name=input('')\n",
    "Session_Name=Session_Name.replace(\" \",\"_\")\n",
    "\n",
    "\n",
    "WORKSPACE='./Fast-Dreambooth'\n",
    "INSTANCE_NAME=Session_Name\n",
    "OUTPUT_DIR=\"./models/\"+Session_Name\n",
    "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
    "INSTANCE_DIR=SESSION_DIR+'/instance_images'\n",
    "CAPTIONS_DIR=SESSION_DIR+'/captions'\n",
    "MDLPTH=str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')\n",
    "\n",
    "if os.path.exists(str(SESSION_DIR)):\n",
    "  mdls=[ckpt for ckpt in listdir(SESSION_DIR) if ckpt.split(\".\")[-1]==\"ckpt\"]\n",
    "  if not os.path.exists(MDLPTH) and '.ckpt' in str(mdls):\n",
    "\n",
    "    def f(n):\n",
    "      k=0\n",
    "      for i in mdls:\n",
    "        if k==n:\n",
    "          !mv \"$SESSION_DIR/$i\" $MDLPTH\n",
    "        k=k+1\n",
    "\n",
    "    k=0\n",
    "    print('\u001B[1;33mNo final checkpoint model found, select which intermediary checkpoint to use, enter only the number, (000 to skip):\\n\u001B[1;34m')\n",
    "\n",
    "    for i in mdls:\n",
    "      print(str(k)+'- '+i)\n",
    "      k=k+1\n",
    "    n=input()\n",
    "    while int(n)>k-1:\n",
    "      n=input()\n",
    "    if n!=\"000\":\n",
    "      f(int(n))\n",
    "      print('\u001B[1;32mUsing the model '+ mdls[int(n)]+\" ...\")\n",
    "      time.sleep(2)\n",
    "    else:\n",
    "      print('\u001B[1;32mSkipping the intermediary checkpoints.')\n",
    "    del n\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd ./content\n",
    "  resume=False\n",
    "\n",
    "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(MDLPTH):\n",
    "  print('\u001B[1;32mLoading session with no previous model, using the original model or the custom downloaded model')\n",
    "  if MODEL_NAME==\"\":\n",
    "    print('\u001B[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "  else:\n",
    "    print('\u001B[1;32mSession Loaded, proceed to uploading instance images')\n",
    "\n",
    "elif os.path.exists(MDLPTH):\n",
    "  print('\u001B[1;32mSession found, loading the trained model ...')\n",
    "  wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/det.py')\n",
    "  print('\u001B[1;33mDetecting model version...')\n",
    "  Model_Version=check_output('python det.py --MODEL_PATH '+MDLPTH, shell=True).decode('utf-8').replace('\\n', '')\n",
    "  clear_output()\n",
    "  print('\u001B[1;32m'+Model_Version+' Detected')\n",
    "  !rm det.py\n",
    "  if Model_Version=='1.5':\n",
    "    wget.download('https://github.com/CompVis/stable-diffusion/raw/main/configs/stable-diffusion/v1-inference.yaml', out='config.yaml')\n",
    "    print('\u001B[1;32mSession found, loading the trained model ...')\n",
    "    !python ./diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path $MDLPTH --dump_path \"$OUTPUT_DIR\" --original_config_file config.yaml\n",
    "    !rm ./config.yaml\n",
    "\n",
    "  elif Model_Version=='V2.1-512px':\n",
    "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffv2.py', out='convertodiff.py')\n",
    "    print('\u001B[1;32mSession found, loading the trained model ...')\n",
    "    !python ./convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1-base\n",
    "    !rm ./convertodiff.py\n",
    "\n",
    "  elif Model_Version=='V2.1-768px':\n",
    "    wget.download('https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertodiffv2-768.py', out='convertodiff.py')\n",
    "    print('\u001B[1;32mSession found, loading the trained model ...')\n",
    "    !python ./convertodiff.py \"$MDLPTH\" \"$OUTPUT_DIR\" --v2 --reference_model stabilityai/stable-diffusion-2-1\n",
    "    !rm ./convertodiff.py\n",
    "\n",
    "\n",
    "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "    resume=True\n",
    "    clear_output()\n",
    "    print('\u001B[1;32mSession loaded.')\n",
    "  else:\n",
    "    if not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "      print('\u001B[1;31mConversion error, if the error persists, remove the CKPT file from the current session folder')\n",
    "\n",
    "elif not os.path.exists(str(SESSION_DIR)):\n",
    "    %mkdir -p \"$INSTANCE_DIR\"\n",
    "    print('\u001B[1;32mCreating session...')\n",
    "    if MODEL_NAME==\"\":\n",
    "      print('\u001B[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "    else:\n",
    "      print('\u001B[1;32mSession created, proceed to uploading instance images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cH_NS8MKxRb",
    "outputId": "49be77c2-6bb0-4359-9be8-698290503efa",
    "ExecuteTime": {
     "end_time": "2023-11-24T00:42:45.867079Z",
     "start_time": "2023-11-24T00:42:41.665792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  |███████████████| 9/9 Uploaded\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1;32mDone, proceed to the next cell\n"
     ]
    }
   ],
   "source": [
    "#@markdown # Instanzbilder\n",
    "#@markdown **Alle Bilder jeder Kategorie müssen einen einzigartigen Identifier besitzen!**\n",
    "#@markdown - Beispiel: katze (1).png, katze (2).png etc.\n",
    "\n",
    "import shutil\n",
    "import time\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from io import BytesIO\n",
    "import wget\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd ./content\n",
    "  if not os.path.exists(\"./smart_crop.py\"):\n",
    "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/smart_crop.py')\n",
    "  from smart_crop import *\n",
    "\n",
    "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
    "\n",
    "if Remove_existing_instance_images:\n",
    "  if os.path.exists(str(INSTANCE_DIR)):\n",
    "    !rm -r \"$INSTANCE_DIR\"\n",
    "  if os.path.exists(str(CAPTIONS_DIR)):\n",
    "    !rm -r \"$CAPTIONS_DIR\"\n",
    "\n",
    "if not os.path.exists(str(INSTANCE_DIR)):\n",
    "  %mkdir -p \"$INSTANCE_DIR\"\n",
    "if not os.path.exists(str(CAPTIONS_DIR)):\n",
    "  %mkdir -p \"$CAPTIONS_DIR\"\n",
    "\n",
    "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
    "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
    "\n",
    "IMAGES_FOLDER=\"images\" #@param{type: 'string'}\n",
    "\n",
    "Crop_images= True #@param{type: 'boolean'}\n",
    "Crop_size = 512 #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"] {type:\"raw\"}\n",
    "\n",
    "while not os.path.exists(str(IMAGES_FOLDER)):\n",
    "  print('\u001B[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path :')\n",
    "  IMAGES_FOLDER=input('')\n",
    "\n",
    "if IMAGES_FOLDER!=\"\":\n",
    "  if os.path.exists(IMAGES_FOLDER+\"/.ipynb_checkpoints\"):\n",
    "    %rm -r \"$IMAGES_FOLDER\"\"/.ipynb_checkpoints\"\n",
    "\n",
    "  with capture.capture_output() as cap:\n",
    "    !mv $IMAGES_FOLDER/*.txt $CAPTIONS_DIR\n",
    "  if Crop_images:\n",
    "    for filename in tqdm(os.listdir(IMAGES_FOLDER), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
    "      extension = filename.split(\".\")[-1]\n",
    "      identifier=filename.split(\".\")[0]\n",
    "      new_path_with_file = os.path.join(INSTANCE_DIR, filename)\n",
    "      file = Image.open(IMAGES_FOLDER+\"/\"+filename)\n",
    "      width, height = file.size\n",
    "      if file.size !=(Crop_size, Crop_size):\n",
    "        image=crop_image(file, Crop_size)\n",
    "        if extension.upper()==\"JPG\" or extension.upper()==\"jpg\":\n",
    "            image[0] = image[0].convert(\"RGB\")\n",
    "            image[0].save(new_path_with_file, format=\"JPEG\", quality = 100)\n",
    "        else:\n",
    "            image[0].save(new_path_with_file, format=extension.upper())\n",
    "      else:\n",
    "        !cp \"$IMAGES_FOLDER/$filename\" \"$INSTANCE_DIR\"\n",
    "\n",
    "  else:\n",
    "    for filename in tqdm(os.listdir(IMAGES_FOLDER), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
    "      %cp -r \"$IMAGES_FOLDER/$filename\" \"$INSTANCE_DIR\"\n",
    "\n",
    "  print('\\n\u001B[1;32mDone, proceed to the next cell')\n",
    "\n",
    "with capture.capture_output() as cap:\n",
    "  %cd \"$INSTANCE_DIR\"\n",
    "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
    "  %cd \"$CAPTIONS_DIR\"\n",
    "  !find . -name \"* *\" -type f | rename 's/ /-/g'\n",
    "\n",
    "  %cd $SESSION_DIR\n",
    "  !rm instance_images.zip captions.zip\n",
    "  !zip -r instance_images instance_images\n",
    "  !zip -r captions captions\n",
    "  %cd ../../../../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ8qqzdDMYq0"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a66yyROaMaeY",
    "outputId": "e343d165-c190-4344-96b7-8b5ab36affd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;33mTraining the UNet...\u001B[0m\n",
      "The following values were not passed to `accelerate launch` and had defaults used instead:\r\n",
      "\t`--num_processes` was set to a value of `0`\r\n",
      "\t`--num_machines` was set to a value of `1`\r\n",
      "\t`--mixed_precision` was set to a value of `'no'`\r\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\r\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Philipp/PycharmProjects/pythonProject/tests/content/./diffusers/examples/dreambooth/train_dreambooth.py\", line 803, in <module>\r\n",
      "    main()\r\n",
      "  File \"/Users/Philipp/PycharmProjects/pythonProject/tests/content/./diffusers/examples/dreambooth/train_dreambooth.py\", line 443, in main\r\n",
      "    accelerator = Accelerator(\r\n",
      "                  ^^^^^^^^^^^^\r\n",
      "TypeError: Accelerator.__init__() got an unexpected keyword argument 'logging_dir'\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\r\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 951, in <module>\r\n",
      "    main()\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 947, in main\r\n",
      "    launch_command(args)\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 941, in launch_command\r\n",
      "    simple_launcher(args)\r\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/accelerate/commands/launch.py\", line 603, in simple_launcher\r\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\r\n",
      "subprocess.CalledProcessError: Command '['/usr/local/bin/python3.11', './diffusers/examples/dreambooth/train_dreambooth.py', '--offset_noise', '--image_captions_filename', '--train_only_unet', '--save_starting_step=500', '--save_n_steps=0', '--Session_dir=./Fast-Dreambooth/Sessions/sketchySounds', '--pretrained_model_name_or_path=./stable-diffusion-v1-5', '--instance_data_dir=./Fast-Dreambooth/Sessions/sketchySounds/instance_images', '--output_dir=./models/sketchySounds', '--captions_dir=./Fast-Dreambooth/Sessions/sketchySounds/captions', '--instance_prompt=', '--seed=855055', '--resolution=512', '--mixed_precision=fp16', '--train_batch_size=1', '--gradient_accumulation_steps=1', '--use_8bit_adam', '--learning_rate=2e-06', '--lr_scheduler=linear', '--lr_warmup_steps=0', '--max_train_steps=1500']' returned non-zero exit status 1.\r\n",
      "\u001B[1;31mSomething went wrong\n"
     ]
    }
   ],
   "source": [
    "#@markdown #DreamBooth starten\n",
    "#@markdown ---\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from subprocess import getoutput\n",
    "import time\n",
    "import random\n",
    "\n",
    "if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
    "  %rm -r $INSTANCE_DIR\"/.ipynb_checkpoints\"\n",
    "\n",
    "if os.path.exists(CAPTIONS_DIR+\"/.ipynb_checkpoints\"):\n",
    "  %rm -r $CAPTIONS_DIR\"/.ipynb_checkpoints\"\n",
    "\n",
    "#@markdown Fortsetzung des Trainings des bestehenden Modells (bei Unzufriedenheit mit dem Ergebnis)\n",
    "Resume_Training = False #@param {type:\"boolean\"}\n",
    "\n",
    "if resume and not Resume_Training:\n",
    "  print('\u001B[1;31mOverwrite your previously trained model ? answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001B[0m')\n",
    "  while True:\n",
    "    answer_from_user=input('')\n",
    "    if answer_from_user== 'no':\n",
    "      Resume_Training = True\n",
    "      break\n",
    "    elif answer_from_user== 'yes':\n",
    "      Resume_Training = False\n",
    "      resume= False\n",
    "      break\n",
    "\n",
    "while not Resume_Training and MODEL_NAME==\"\":\n",
    "  print('\u001B[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "  time.sleep(5)\n",
    "\n",
    "\n",
    "#@markdown Diese Einstellungen sind für einen Datensatz mit 10 Bildern\n",
    "#@markdown - Start mit 1500 Schritten oder weniger. Wenn nicht genug, weitere 200\n",
    "#@markdown - Schritte auf 0 setzen, um nur den text_encoder zu testen\n",
    "MODELT_NAME=MODEL_NAME\n",
    "UNet_Training_Steps=1500 #@param{type: 'number'}\n",
    "UNet_Learning_Rate = 2e-6 #@param [\"2e-5\",\"1e-5\",\"9e-6\",\"8e-6\",\"7e-6\",\"6e-6\",\"5e-6\", \"4e-6\", \"3e-6\", \"2e-6\"] {type:\"raw\"}\n",
    "untlr=UNet_Learning_Rate\n",
    "\n",
    "#@markdown 200-450 Schritte sind ausreichend für einen kleinen Datensatz\n",
    "#@markdown - Diese Zahl sollte klein gehalten werden, um Overfitting zu vermeiden\n",
    "Text_Encoder_Training_Steps=350 #@param{type: 'number'}\n",
    "\n",
    "#@markdown Lernrate für den text_encoder -> Klein halten, um Overfitting zu vermeiden\n",
    "Text_Encoder_Learning_Rate = 1e-6 #@param [\"2e-6\", \"1e-6\",\"8e-7\",\"6e-7\",\"5e-7\",\"4e-7\"] {type:\"raw\"}\n",
    "txlr=Text_Encoder_Learning_Rate\n",
    "\n",
    "trnonltxt=\"\"\n",
    "if UNet_Training_Steps==0:\n",
    "   trnonltxt=\"--train_only_text_encoder\"\n",
    "\n",
    "Seed=''\n",
    "\n",
    "ofstnse=\"\"\n",
    "#@markdown Für Style-Training aktivieren!\n",
    "Offset_Noise = True #@param {type:\"boolean\"}\n",
    "\n",
    "if Offset_Noise:\n",
    "  ofstnse=\"--offset_noise\"\n",
    "\n",
    "#@markdown Captions für jedes Bild aus einer Textdatei mit demselben Namen lesen\n",
    "External_Captions = False #@param {type:\"boolean\"}\n",
    "extrnlcptn=\"\"\n",
    "if External_Captions:\n",
    "  extrnlcptn=\"--external_captions\"\n",
    "\n",
    "#@markdown Höhere Auflösung = höhere Qualität\n",
    "#@markdown - Instanzbilder müssen auch mindestens diese Größe sein\n",
    "Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
    "Res=int(Resolution)\n",
    "\n",
    "fp16 = True\n",
    "\n",
    "if Seed =='' or Seed=='0':\n",
    "  Seed=random.randint(1, 999999)\n",
    "else:\n",
    "  Seed=int(Seed)\n",
    "\n",
    "if fp16:\n",
    "  prec=\"fp16\"\n",
    "else:\n",
    "  prec=\"no\"\n",
    "\n",
    "precision=prec\n",
    "\n",
    "resuming=\"\"\n",
    "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "  MODELT_NAME=OUTPUT_DIR\n",
    "  print('\u001B[1;32mResuming Training...\u001B[0m')\n",
    "  resuming=\"Yes\"\n",
    "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
    "  print('\u001B[1;31mPrevious model not found, training a new model...\u001B[0m')\n",
    "  MODELT_NAME=MODEL_NAME\n",
    "  while MODEL_NAME==\"\":\n",
    "    print('\u001B[1;31mNo model found, use the \"Model Download\" cell to download a model.')\n",
    "    time.sleep(5)\n",
    "\n",
    "V2=False\n",
    "!pwd\n",
    "if os.path.getsize(MODELT_NAME+\"/text_encoder/pytorch_model.bin\") > 670901463:\n",
    "  V2=True\n",
    "\n",
    "s = getoutput('nvidia-smi')\n",
    "GCUNET=\"--gradient_checkpointing\"\n",
    "TexRes=Res\n",
    "if Res<=768:\n",
    "  GCUNET=\"\"\n",
    "\n",
    "if V2:\n",
    "  if Res>704:\n",
    "    GCUNET=\"--gradient_checkpointing\"\n",
    "  if Res>576:\n",
    "    TexRes=576\n",
    "\n",
    "if 'A100' in s :\n",
    "   GCUNET=\"\"\n",
    "   TexRes=Res\n",
    "\n",
    "\n",
    "Enable_text_encoder_training= True\n",
    "\n",
    "if Text_Encoder_Training_Steps==0 :\n",
    "   Enable_text_encoder_training= False\n",
    "else:\n",
    "  stptxt=Text_Encoder_Training_Steps\n",
    "\n",
    "\n",
    "#@markdown ---------------------------\n",
    "#@markdown Sollen die Checkpoints alle x Schritte gespeichert werden (min. 200!)?\n",
    "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
    "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
    "if Save_Checkpoint_Every==None:\n",
    "  Save_Checkpoint_Every=1\n",
    "stp=0\n",
    "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
    "if Start_saving_from_the_step==None:\n",
    "  Start_saving_from_the_step=0\n",
    "if (Start_saving_from_the_step < 200):\n",
    "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
    "stpsv=Start_saving_from_the_step\n",
    "if Save_Checkpoint_Every_n_Steps:\n",
    "  stp=Save_Checkpoint_Every\n",
    "\n",
    "def dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
    "\n",
    "    !python3.11 -m accelerate.commands.launch ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $trnonltxt \\\n",
    "    $extrnlcptn \\\n",
    "    $ofstnse \\\n",
    "    --image_captions_filename \\\n",
    "    --train_text_encoder \\\n",
    "    --dump_only_text_encoder \\\n",
    "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=$TexRes \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=$txlr \\\n",
    "    --lr_scheduler=\"linear\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "def train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps):\n",
    "    clear_output()\n",
    "    if resuming==\"Yes\":\n",
    "      print('\u001B[1;32mResuming Training...\u001B[0m')\n",
    "    print('\u001B[1;33mTraining the UNet...\u001B[0m')\n",
    "    !python3.11 -m accelerate.commands.launch ./diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    $extrnlcptn \\\n",
    "    $ofstnse \\\n",
    "    --image_captions_filename \\\n",
    "    --train_only_unet \\\n",
    "    --save_starting_step=$stpsv \\\n",
    "    --save_n_steps=$stp \\\n",
    "    --Session_dir=$SESSION_DIR \\\n",
    "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
    "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "    --output_dir=\"$OUTPUT_DIR\" \\\n",
    "    --captions_dir=\"$CAPTIONS_DIR\" \\\n",
    "    --instance_prompt=\"$PT\" \\\n",
    "    --seed=$Seed \\\n",
    "    --resolution=$Res \\\n",
    "    --mixed_precision=$precision \\\n",
    "    --train_batch_size=1 \\\n",
    "    --gradient_accumulation_steps=1 $GCUNET \\\n",
    "    --use_8bit_adam \\\n",
    "    --learning_rate=$untlr \\\n",
    "    --lr_scheduler=\"linear\" \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --max_train_steps=$Training_Steps\n",
    "\n",
    "\n",
    "if Enable_text_encoder_training :\n",
    "  print('\u001B[1;33mTraining the text encoder...\u001B[0m')\n",
    "  if os.path.exists(OUTPUT_DIR+'/'+'text_encoder_trained'):\n",
    "    %rm -r $OUTPUT_DIR\"/text_encoder_trained\"\n",
    "  dump_only_textenc(trnonltxt, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
    "\n",
    "\n",
    "if UNet_Training_Steps!=0:\n",
    "  train_only_unet(stpsv, stp, SESSION_DIR, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, Res, precision, Training_Steps=UNet_Training_Steps)\n",
    "\n",
    "if UNet_Training_Steps==0 and Text_Encoder_Training_Steps==0 :\n",
    "  print('\u001B[1;32mNothing to do')\n",
    "else:\n",
    "  if os.path.exists('./models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
    "    prc=\"--fp16\" if precision==\"fp16\" else \"\"\n",
    "    ### TODO: Schauen, ob man statt CKPT lieber anderes Format nimmt\n",
    "    !python ./diffusers/scripts/convertosdv2.py $prc $OUTPUT_DIR $SESSION_DIR/$Session_Name\".ckpt\"\n",
    "    clear_output()\n",
    "    if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
    "      clear_output()\n",
    "      print(\"\u001B[1;32mDONE, the CKPT model is in your sessions folder\")\n",
    "    else:\n",
    "      print(\"\u001B[1;31mSomething went wrong\")\n",
    "  else:\n",
    "    print(\"\u001B[1;31mSomething went wrong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "venv",
   "language": "python",
   "display_name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
